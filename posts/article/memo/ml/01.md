---
title: "01"
date: 2021-04-07T10:24:06+09:00
draft: true
---

## パターン認識

- パターン認識: 与えられたパターンをそれが属するカテゴリに対応付ける操作

- パターン:空間的や時間的に観測可能な事象であって、観測された事象どうしが同一であるか否かを判定できるような性質を備えているもの

- カテゴリ：パターン認識の結果、同等とみなされるパターンの集合概念

- 識別関数: 任意のパターンをそれが属するカテゴリに対応付ける変換

未知の識別関数を構成したい
→様々なパターンに対してカテゴリを調べて識別関数を求める
→全てのパターンに対してデータを用意してカテゴリを調べるのは不可能
→現実的な量のデータから、データに含まれないパターンに対して識別関数の値を推定する
↓
パターン認識の問題は識別関数の学習の問題になる！
学習に用いていないデータをうまく補間できるか(汎化能力)が重要！

- 訓練標本: 属するカテゴリが既知のパターン
- 統計的パターン認識：訓練標本の統計的な性質を利用して識別関数を学習する

## 識別関数のよさを測る規準

### 最大事後確率則

- 最大事後確率則(maximum a posteriori probability rule):入力パターンが属する可能性が最も高いカテゴリを選ぶ
  - これは、$x$を事後確率が最大になるカテゴリに分類することに対応

$$\argmax_y p(y\vert x)$$

- 決定領域を次のように設定することと等価

$D_y = \lbrace x \vert \forall y' \neq y p(y\vert x) \geq p(y' \vert x) \rbrace$

### 最小後識別率則

- 最小後識別率則：パターンが誤って分類される確率を最小にするように識別関数を決定

- $p_e(y\to y')$:カテゴリ$y$に属するパターンが誤ってカテゴリ$y'$に分類される確率

$$p_e(y \to y') = \int_{x \in D_{y'}} p(x \vert y) dx$$

- $p_e(y)$:カテゴリ$y$に属するパターンが誤って他のカテゴリに分類される確率

$$p_e(y) = \sum_{y'\neq y}p_e(y\to y')$$

これは以下のように変形できる

$$p_e(y) = 1 - \int_{x \in D_y} p(x\vert y) dx$$

- 全体の誤識別率$p_e$:

$$p_e = \sum_{y=1}^c p_e(y) p(y)$$

- 最小誤識別率則では$p_e$が最小になるように識別関数を決定する

実は最小誤識別率則は最大事後確率則と等価！スライドp.40

### ベイズ決定則

誤識別を最小にするより損失を最小にした方がいい場合(例:降水確率40%で傘を持っていくか？)

- ベイズ決定則:誤識別の時の損失を最小にするように識別

$$R(y' \vert x) = \sum_{y} l_{y,y'} p(y \vert x)$$



- この講義では最大事後確率則を用いる

  - 最大事後確率則と最小誤識別率則は等価
  - ベイズ決定則は現実的に損失の値がはっきりしなかったり計算が複雑になる
  - 損失が一定のベイズ決定則は最大事後確率則と等価

### 識別器の構成

最大事後確率則

$$f(x) =\argmax_y p(y\vert x)$$

- 訓練標本を次のように生成すると仮定

  - 訓練標本を$p(y)$に従ってランダムに選び、$p(x\vert y)$に従ってランダムに取り出す
  - 標本$\lbrace (x_i,y_i) \rbrace$は**独立に同一な分布**(independent and identically distributed; i.i.d.)とみなせる

ベイズの定理

$p(y\vert x) $を$y$に対して最大化

$$p(y\vert x) = \frac{p(x \vert y) p(y)}{p(x)} \propto p(x \vert y) p(y)$$

-> $p(x \vert y) p(y)$を最大化

-> $p(y)$は訓練標本内のカテゴリ$y$の割合と考えられる

-> $p(x \vert y)$が分かればよい

-> 条件付きでない確率$p(x)$を推定する問題を考えれば、$y$に属する標本から計算することで$p(x \vert y)$が求められる

宿題：定量化して議論する　個性のある内容が望ましい

## 第2回

### パターン認識

- 事後確率$p(y \vert x)$：与えられたパターン$x$がクラス$y$に属する確率

- 事後確率を最大にするカテゴリにパターンを分類すれば、パターンの誤識別率が最小になる

- ベイズの定理を用いれば

$$p(y\vert x) = \frac{p(x \vert y) p(y)}{p(x)} \propto p(x \vert y) p(y)$$

- (事後確率)$\propto$(条件付け確率)・(事前確率)を得る

- 条件付き確率と事前確率を推定する！

### 確率の推定

- 事前確率・・・標本の割合で推定

$$\hat{p}(y) = \frac{n_y}{n}$$

- 条件付確率は連続的な確率分布なので、事前確率のように単純には推定できない

- $y$に属する$n_y$個の標本のみを見ればよい

- 簡単のため、$p(x)$を$\lbrace x_i \rbrace$から推定する問題(=条件付きでない確率)を考える

### 最尤推定法

- パラメトリック法:有限次元のパラメータを持つパラメトリックモデルを用いて確率密度関数を推定する
  - 最尤推定法
  - ベイズ推定法

- ノンパラメトリック法：それ以外の方法

- 訓練標本

$$p(x_1,x_2,\ldots,x_n) =$$

### ガウス最尤推定によるパターン認識
